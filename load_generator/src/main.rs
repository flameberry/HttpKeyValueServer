use std::env;
use std::io::Write;
use std::sync::{Arc, Mutex};
use std::thread::JoinHandle;
use std::time::{Duration, Instant, SystemTime};

use rand::Rng;
use reqwest::Client as NonBlockingClient;
use reqwest::blocking::Client as BlockingClient;
use serde::Serialize;
use uuid::Uuid;

const BASE_URL: &str = "http://127.0.0.1:3000/kv";

#[derive(Serialize)]
struct PutPayload {
    value: String,
}

/// Populates the KV store with initial keys for read-heavy workloads.
async fn populate_keys(num_keys: u32) -> Vec<String> {
    println!("Populating {} keys...", num_keys);
    let client = NonBlockingClient::new();
    let mut keys: Vec<String> = Vec::new();
    let mut success_count = 0;

    for i in 0..num_keys {
        let uuid: String = Uuid::new_v4().to_string();

        let payload = PutPayload {
            value: format!("Value generated by `populate_keys` for the key: {}", uuid),
        };

        match client.put(format!("{}/{}", BASE_URL, uuid)).json(&payload).send().await {
            Ok(response) => {
                if response.status().is_success() {
                    keys.push(uuid);
                    success_count += 1;
                }
            }
            Err(err) => eprintln!("Request Failed: {}", err),
        }

        if (i + 1) % 1000 == 0 {
            println!("Populated {}/{} keys", i + 1, num_keys);
        }
    }
    println!("Finished populating. Successfully stored {} keys.", success_count);
    keys
}

#[derive(Debug, Default, Clone)]
struct ThreadMetrics {
    total_successful_requests: u64,
    total_request_duration: Duration,
}

fn print_final_metrics(workload: &str, threads: usize, final_metrics: &ThreadMetrics, duration: Duration) {
    let total_successful_requests = final_metrics.total_successful_requests;
    let total_elapsed_time_sec = duration.as_secs_f64();

    println!("\n--- Workload Results: {} ({} threads) ---", workload, threads);
    println!("Total successful requests: {}", total_successful_requests);
    println!("Total test duration: {:.2} seconds", total_elapsed_time_sec);

    // Calculate Average Throughput (Requests per second)
    if total_elapsed_time_sec > 0.0 {
        let avg_throughput = total_successful_requests as f64 / total_elapsed_time_sec;
        println!("**Average Throughput**: **{:.2} requests/sec**", avg_throughput);
    } else {
        println!("Average Throughput: Cannot calculate (duration is zero)");
    }

    // Calculate Average Response Time
    if total_successful_requests > 0 {
        let total_duration_ms = final_metrics.total_request_duration.as_millis();
        let avg_response_time_ms = total_duration_ms as f64 / total_successful_requests as f64;
        println!("**Average Response Time**: **{:.2} ms**", avg_response_time_ms);
    } else {
        println!("Average Response Time: Cannot calculate (no successful requests)");
    }
    println!("-------------------------------------------");
}

fn run_experiment(
    workload_type: &str,
    num_threads: usize,
    duration: Duration,
    keys: Option<Arc<Vec<String>>>,
) -> (f64, f64) {
    println!(
        "Starting experiment: Workload='{}', Threads={}, Duration={:?}...",
        workload_type, num_threads, duration
    );

    let start = SystemTime::now();
    let shared_metrics = Arc::new(Mutex::new(ThreadMetrics::default()));

    let handles: Vec<JoinHandle<()>> = (0..num_threads)
        .map(|_| {
            let metrics_clone = Arc::clone(&shared_metrics);
            let keys_ref = keys.clone();
            let w_type = workload_type.to_string();

            std::thread::spawn(move || {
                let client = BlockingClient::new();
                let mut rng = rand::rng();
                let mut thread_metrics = ThreadMetrics::default();

                while start.elapsed().unwrap_or(Duration::ZERO) <= duration {
                    let request_start = Instant::now();
                    let mut success = false;

                    match w_type.as_str() {
                        "put_all" => {
                            let uuid = Uuid::new_v4().to_string();
                            let payload = PutPayload {
                                value: format!("Value put_all {}", uuid),
                            };
                            if client
                                .put(format!("{}/{}", BASE_URL, uuid))
                                .json(&payload)
                                .send()
                                .is_ok()
                            {
                                success = true;
                            }
                        }
                        "get_all" => {
                            if let Some(k) = &keys_ref {
                                if !k.is_empty() {
                                    let id = &k[rng.random_range(0..k.len())];
                                    if client.get(format!("{}/{}", BASE_URL, id)).send().is_ok() {
                                        success = true;
                                    }
                                }
                            }
                        }
                        "get_popular" => {
                            if let Some(k) = &keys_ref {
                                if !k.is_empty() {
                                    // Simulate "popular" by restricting to first 20% of keys
                                    let limit = (k.len() / 5).max(1);
                                    let id = &k[rng.random_range(0..limit)];
                                    if client.get(format!("{}/{}", BASE_URL, id)).send().is_ok() {
                                        success = true;
                                    }
                                }
                            }
                        }
                        "mixed" => {
                            // 50% Get, 50% Put
                            if rng.random_bool(0.5) {
                                let uuid = Uuid::new_v4().to_string();
                                let payload = PutPayload {
                                    value: format!("Value mixed {}", uuid),
                                };
                                if client
                                    .put(format!("{}/{}", BASE_URL, uuid))
                                    .json(&payload)
                                    .send()
                                    .is_ok()
                                {
                                    success = true;
                                }
                            } else if let Some(k) = &keys_ref {
                                if !k.is_empty() {
                                    let id = &k[rng.random_range(0..k.len())];
                                    if client.get(format!("{}/{}", BASE_URL, id)).send().is_ok() {
                                        success = true;
                                    }
                                }
                            }
                        }
                        _ => {} // Should not happen
                    }

                    if success {
                        let req_dur = request_start.elapsed();
                        thread_metrics.total_successful_requests += 1;
                        thread_metrics.total_request_duration += req_dur;
                    }
                }

                // Aggregate results
                let mut global = metrics_clone.lock().unwrap();
                global.total_successful_requests += thread_metrics.total_successful_requests;
                global.total_request_duration += thread_metrics.total_request_duration;
            })
        })
        .collect();

    for handle in handles {
        handle.join().unwrap();
    }

    let elapsed = start.elapsed().unwrap_or(duration);
    let final_metrics = shared_metrics.lock().unwrap();
    print_final_metrics(workload_type, num_threads, &final_metrics, elapsed);

    let total_time = elapsed.as_secs_f64();
    let throughput = if total_time > 0.0 {
        final_metrics.total_successful_requests as f64 / total_time
    } else {
        0.0
    };
    let avg_latency = if final_metrics.total_successful_requests > 0 {
        final_metrics.total_request_duration.as_millis() as f64 / final_metrics.total_successful_requests as f64
    } else {
        0.0
    };

    (throughput, avg_latency)
}

async fn run_automated_experiments(workload: &str, duration: Duration) {
    // Populate keys if necessary (for read-heavy workloads)
    let keys = if workload == "get_all" || workload == "get_popular" || workload == "mixed" {
        let k = populate_keys(10_000).await;
        Some(Arc::new(k))
    } else {
        None
    };

    let filename = format!("{}_results.csv", workload);
    let mut file = std::fs::File::create(&filename).expect("Could not create CSV file");
    writeln!(&mut file, "Threads,Throughput,AvgResponseTime").expect("Could not write header");

    println!(
        "Starting automated experiments for workload: {}. Results will be saved to {}",
        workload, filename
    );

    let (mut last_throughput, mut _last_latency) = (0.0, 0.0);
    let threshold = 0.05;

    for threads in (2..32).step_by(2) {
        println!("\nRunning with {} threads...", threads);
        let (throughput, latency) = run_experiment(workload, threads, duration, keys.clone());
        writeln!(&mut file, "{},{:.2},{:.2}", threads, throughput, latency).expect("Could not write record");

        if throughput - last_throughput <= threshold * last_throughput {
            break;
        }

        (last_throughput, _last_latency) = (throughput, latency);
        std::thread::sleep(Duration::from_secs(2)); // Optional: Cool down
    }

    println!("\nAutomated experiments completed. Results saved to {}", filename);
}

#[tokio::main]
async fn main() {
    let args: Vec<String> = env::args().collect();

    if args.len() < 2 {
        println!("Usage:");
        println!("  Single run: load_generator <workload> <threads> [duration_seconds]");
        println!("  Auto run:   load_generator auto <workload> [duration_seconds]");
        println!("Workloads: put_all, get_all, get_popular, mixed");
        return;
    }

    let mode_or_workload = &args[1];

    if mode_or_workload == "auto" {
        if args.len() < 3 {
            println!("Usage: load_generator auto <workload> [duration_seconds]");
            return;
        }
        let workload = &args[2];
        let duration_sec: u64 = args.get(3).map(|s| s.parse().unwrap_or(300)).unwrap_or(300);
        run_automated_experiments(workload, Duration::from_secs(duration_sec)).await;
    } else {
        if args.len() < 3 {
            println!("Usage: load_generator <workload> <threads> [duration_seconds]");
            return;
        }
        let workload = mode_or_workload;
        let threads: usize = args[2].parse().expect("Invalid thread count");
        let duration_sec: u64 = args.get(3).map(|s| s.parse().unwrap_or(300)).unwrap_or(300);
        let duration = Duration::from_secs(duration_sec);

        // Populate keys if necessary (for read-heavy workloads)
        let keys = if workload == "get_all" || workload == "get_popular" || workload == "mixed" {
            let k = populate_keys(10_000).await;
            Some(Arc::new(k))
        } else {
            None
        };

        run_experiment(workload, threads, duration, keys);
    }
}
